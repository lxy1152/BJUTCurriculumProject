# 专注度检测系统
![screenshots](/Graduation/screenshots.png)

## 前言
本分支中的项目是我的毕业设计，我简单介绍一下项目的要求以及我在完成毕设后的一点感想。

### 任务书要求
题目：专注度检测系统的设计与实现
1. 通过摄像头以及脑波模块采集学生在上课期间的表情、眼动、脑波数据
2. 对采集到的数据进行分析，得到学生在上课时的专注度数值
3. 数据每分钟保存
4. 提供简单的图形化界面
5. 考虑工程伦理问题

### 任务书要求扩展
以下内容是我针对任务书中的内容所作的扩展，论文的撰写以及项目的实现均按照以下要求执行。项目需要使用的TGAM脑波模块请自行购买。当然没有TGAM模块程序也是可以运行的，只不过没有脑波的数据。
1. 连接TGAM脑波模块，管理人员可以调节端口、波特率等信息以保证设备的正常运行
2. 在学生上课期间，采集学生的表情、眼动以及脑波数据
3. 在采集到相应数据后，对数据进行分析。脑波数据使用蓝牙进行传输，表情和眼动数据则通过Face++平台获取
4. 在获得3中的结果后，根据相应公式计算学生的专注度
5. 表情、眼动以及脑波数据还有视频文件每分钟存储，前三者为csv文件，最后为mp4文件
6. 用户可以在系统上进行登录注册操作
7. 学生可以通过系统查看由设备采集并分析的数据
8. 教师和系统管理员可以通过系统执行实时监控、录像回放、管理教学计划功能
9. 实现班级的概念，实现教师与学生的一对多关系

### 论文组织结构
论文的撰写按照软件工程流程进行。
- 第一章绪论：包含研究背景、研究意义、研究现状、研究内容以及本文组织结构。
- 第二章相关算法介绍：论文使用了[Face++平台的眼动数据处理算法](http://techsupport.megvii.com/hc/kb/article/1149403/)，在此部分对它进行介绍。
- 第三章可行性与需求分析：包含可行性分析、系统需求、性能需求、业务逻辑、故障处理要求以及用例图。
- 第四章概要设计：包含引言、总体设计、系统功能模块设计、图形界面设计以及数据库设计。
- 第五章详细设计与系统实现：包含环境介绍以及各功能模块的实现。
- 第六章系统测试：包含硬件设备功能测试、软件模块功能测试、集成测试、性能测试以及设备故障测试。
- 结论：包含论文的总结以及存在的不足。

### 毕设的心得
做毕设选一个好的老师真是太重要了，在此我非常感谢我的导师。因为疫情不能返校，但老师依然坚持每周开一次视频会议，交流毕设的进度和问题。论文也要求很严格，最终在第五稿的时候作为终稿进行了提交。我简单说说在我完成毕设以后的一点心得。<br>在毕设的选题上，为了图省事，最好选择工程实践类的论文，这类论文的题目一般都是某某系统的设计与实现。但是啊，也不能选太简单的题目，比如那些没有用到其他的工具或平台的题目。举个例子，比如纯用Java、Python等实现的管理系统。因为它们使用的技术较为封闭，所以程序比较好写，但是论文不好写啊，研究现状那部分的你能写个啥。当然对于大佬，完全可以选择其他更难的题目。<br>在时间的安排上，北工大一般应该是6月初安排答辩。建议寒假的时候就把程序全部写完，这样开学后的三月、四月不会影响你找工作（面试、签三方协议、转档案等都很耗时间）或者其他的安排。在四月中下旬就可以开始写论文了，如果程序是自己写的，一般论文初稿一周就能写完。之后就要积极和导师沟通，多问多改。<br>在论文的格式上，一定要注意按照学校要求的格式来写。都快毕业了，别给自己找不痛快，学校的要求是什么就按照什么来。<br>在论文答辩上，因为今年是线上答辩，所以没有什么参考价值，我就不说了。有一点就是ppt要做的好看，字别放太多，放关键字就行。其他的内容就问自己的导师吧。

## 开发目的
提供一个可供学生、教师与系统管理员使用的，支持数据采集、数据处理、数据展示、数据存储的可视化教学系统。

## 开发环境
- Python 3.7.0
- JavaScript
- C#
- SQLite

## 使用环境
现代化的浏览器，如火狐、Chrome等。

## 目录与文件说明
子目录说明：
- `config`：配置文件，采用Python字典存储
- `device`：所需设备的实现类（eye_tracker.py文件与tobii目录下的文件均未使用）；另外由于某些设备需要其他的实现类或调用其他的可执行文件以及动态链接库，这部分也内容保存在了子目录中
- `output`：保存输出文件，包括csv文件以及视频文件，若不存在则系统会负责创建该目录
- `static`：保存前端页面所需的静态资源
- `templates`：html模板，使用jinja2引擎

根目录文件说明：
- `app.py`：系统主入口，执行此文件以运行
- `route.py`：统一注册路由
- `database.py`：负责数据库连接
- `concentration.db`：使用SQLite数据库保存数据，在启动项目前请提前创建好该文件以及其中的表

## Python第三方库依赖
- `Flask`
- `jinja2`
- `opencv`
- `schedule`

## JS第三库依赖
- `syalert.js`
- `datepicker.js`
- `echarts.js`（使用2.x版本，高版本对热力图的支持不友好）
- `moment.js`
- `quill.js`

## 快速使用
注意：没有TGAM模块程序也是可以使用的！只不过数据显示为0！
1. 确保你的摄像头、TGAM模块（可选）可用，确保`concentration.db`文件及其中的表存在
2. 在服务器端导入项目，确保Python环境正常，且已安装上述依赖
2. 在Face++网站上获取API KEY以及API SECRET，并在`.\config\device_config`文件中进行修改
3. 可以采用默认配置，也可以在`config`目录下修改`server_config.py`文件，修改服务器默认端口等信息
4. 启动项目
5. 如果没有修改过配置文件，则在浏览器输入`localhost:5000`即可访问。若修改过，则按修改的配置进行访问

## 如何开发

### 算法说明
除了上述提到的Face++平台提供的算法以外，我自己还提出了三个用于表征专注度的公式。只不过添加这三个公式已经是写论文的末期，论文里面添加了，但是程序里面没有，我也懒得改了。我就简单在这说一下。

#### 如何通过表情数据结果得到专注度数值
![](https://latex.vimsky.com/test.image.latex.php?fmt=svg&val=%255Cdpi%257B150%257D%2520%255Cbg_white%2520%255Clarge%2520CA%253D%25280.5%255Ctimes%2520H%26plus%3B0%255Ctimes%2520A%26plus%3B0%255Ctimes%2520D%26plus%3B0%255Ctimes%2520F%26plus%3B0.1%255Ctimes%2520SA%26plus%3B0.1%255Ctimes%2520SU%26plus%3B0.3%255Ctimes%2520M%2529%255Ctimes%25202&dl=0)
<br>CA表示计算后的专注度数值，H、A、D、F、SA、SU、M分别代表高兴、愤怒、厌恶、恐惧、悲伤、惊奇和中性所体现出的具体数值，该结果由Face++平台提供。为了方便运算，该数值需要转换至0-100范围内，因为在最后需要乘2。

#### 如何通过眼动数据结果得到专注度数值
![](https://latex.vimsky.com/test.image.latex.php?fmt=svg&val=%255Cdpi%257B150%257D%2520%255Cbg_white%2520%255Clarge%2520CB%253D100-0.313%255Ctimes%2520%257Cx-320%257C%252C%257Cy-240%257C%255Cleq%2520%257Cx-320%257C&dl=0)
![](https://latex.vimsky.com/test.image.latex.php?fmt=svg&val=%255Cdpi%257B150%257D%2520%255Cbg_white%2520%255Clarge%2520CB%253D100-0.417%255Ctimes%2520%257Cy-240%257C%252C%257Cx-320%257C%253C%2520%257Cy-240%257C&dl=0)
![](https://latex.vimsky.com/test.image.latex.php?fmt=svg&val=%255Cdpi%257B150%257D%2520%255Cbg_white%2520%255Clarge%2520CB%253D0%252Cx%253C0%255Ccup%2520x%253E640%252Cy%253C0%255Ccup%2520y%253E480&dl=0)
<br>CB表示计算后的专注度数值，x、y分别表示视线汇聚点的横纵坐标值。摄像头拍摄的图片大小为640*480，因此这个公式计算的是视线点和中心位置的偏差。因为结果同样需要转换为0至100范围内，所以前面分别乘0.313和0.417。因为偏离越大，则差值越大，但专注度的值应该越小，所以使用100减去偏差即为最后的结果。

#### 总专注度计算
记脑波专注度结果为CC，该结果可直接通过TGAM模块获取，该数值为0至100范围的整数。则专注度结果为：<br>
![](https://latex.vimsky.com/test.image.latex.php?fmt=svg&val=%255Cdpi%257B150%257D%2520%255Cbg_white%2520%255Clarge%2520C%253D%255Cleft%2520%255Clfloor%2520%255Cleft%2520%2528%2520CA%26plus%3BCB%26plus%3BCC%255Cright%2520%2529%2F3%2520%255Cright%2520%255Crfloor&dl=0)
<br>将上述的三个值相加除3并向下取整就可以得到一个0至100范围内的整数。如果结果处于0-40的区间内，则认为学生不专注；若处于41-70的区间内，则认为学生较专注；若处于71-100的区间内，则认为学生非常专注。

### 配置文件说明
数据库、使用的设备以及服务器的配置都保存在了config目录下，请自行查看。不过我记得我的程序里还是有一些魔法值的，我懒得改了。建议与配置有关的内容都填写在此目录下，方便管理。

### 设备说明
如需添加其他设备，请继承`\device\base_device`，并重写`open_device`以及`detect`函数。在使用上，按逻辑需要先调用`open_device`再调用`detect`。<br>因opencv不能正确的保存mp4格式文件，需要先保存为avi格式文件，再使用ffmpeg软件进行格式转换，并将avi格式文件删除。该软件存放在`\device\native`目录下。同时将使用视频文件的第一帧作为视频缩略图。

### 静态资源说明
静态资源按照css、js、字体（font）、图片（img）进行分类。其中：
1. css、js文件的目录应与其调用方的模板路径相对应。如模板路径为`\templates\home\login.html`，则静态资源文件路径为`\static\css\home\login.css,\static\js\home\login.js`。
2. 图片文件因使用不多，所以并无太多限制，如果你使用的较多，建议对图片文件也进行分类
3. 字体目录中只使用了一个图标字体：[dripicons](http://demo.amitjakhu.com/dripicons/)。如使用其他字体，请创建新的目录（目录名称为字体名称），并放入所需文件

### 模板说明
对于较通用的标签，如导航栏等。建议创建`mybase.html`，其他模板继承该模板并写入独有的内容。

### 数据库说明
使用SQLite3数据库，在项目启动前，请务必确保`concentration.db`文件以及其中的表存在。默认提供的表请见仓库中的`concentration.db`文件。

### 已知问题
1. 在实时监控页面直接点击刷新、按F5、点击浏览器标签中的关闭，将导致摄像头不能正常关闭。
2. 在已经播放一个录像后，选择其他日期的录像不能正常播放。
3. 实时监控功能在保存的录像文件时，有时不能正确删除avi文件。
4. 实时监控功能保存的录像文件在播放时会特别快，感觉是和视频帧率有关系。
5. 因为问题4，所以录像回放页面的视频和数据不能同步显示。
6. 数据库在存储记录时，应该是一分钟一条，但`data_camera_eye`表会一秒钟记录一次（相关的代码已被注释）。
7. css文件的样式我是按照我的笔记本14寸屏幕来设计的，并无过多考虑响应式的问题，所以过大或过小的屏幕在展示上可能会有偏差，请自行调整。